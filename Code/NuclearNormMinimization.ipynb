{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "# optional\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.sparse.linalg import svds\n",
    "from functools import partial\n",
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute\n",
    "\n",
    "\n",
    "train = pd.read_table(\"../Data_competition/X_train.txt\", sep=',',header=None)\n",
    "test = pd.read_table(\"../Data_competition/X_test.txt\",sep=',',header=None)\n",
    "cible=pd.read_table(\"../Data_competition/y_train.txt\",sep=',',header=None)\n",
    "header=pd.read_csv(\"../Data_competition/header.csv\",sep=',',header=None)\n",
    "\n",
    "feature_name=header.drop(header.columns[[2]], axis=1)\n",
    "feature_name=feature_name.drop(feature_name.index[[56,49,30,20,14,0,38]])[3]\n",
    "feature_name\n",
    "feature_name2=header.drop(header.columns[[2]], axis=1)\n",
    "feature_name2=feature_name2.drop(feature_name2.index[[56,49,30,20,14,0,38]])[1]\n",
    "                                 \n",
    "train_via_def=train\n",
    "train_via_def.columns=feature_name2\n",
    "test_via_def=test\n",
    "test_via_def.columns=feature_name2\n",
    "\n",
    "frames=[train_via_def,test_via_def]\n",
    "alldata= pd.concat(frames,keys=['train','test'])\n",
    "alldata['x51']=alldata['x51']-2011 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsc=BiScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances between 4001 samples\n",
      "Computing distances for sample #1/4001, elapsed time: 0.843\n",
      "Computing distances for sample #101/4001, elapsed time: 0.963\n",
      "Computing distances for sample #201/4001, elapsed time: 1.108\n",
      "Computing distances for sample #301/4001, elapsed time: 1.239\n",
      "Computing distances for sample #401/4001, elapsed time: 1.397\n",
      "Computing distances for sample #501/4001, elapsed time: 1.520\n",
      "Computing distances for sample #601/4001, elapsed time: 1.667\n",
      "Computing distances for sample #701/4001, elapsed time: 1.799\n",
      "Computing distances for sample #801/4001, elapsed time: 1.943\n",
      "Computing distances for sample #901/4001, elapsed time: 2.065\n",
      "Computing distances for sample #1001/4001, elapsed time: 2.215\n",
      "Computing distances for sample #1101/4001, elapsed time: 2.363\n",
      "Computing distances for sample #1201/4001, elapsed time: 2.538\n",
      "Computing distances for sample #1301/4001, elapsed time: 2.700\n",
      "Computing distances for sample #1401/4001, elapsed time: 2.849\n",
      "Computing distances for sample #1501/4001, elapsed time: 2.989\n",
      "Computing distances for sample #1601/4001, elapsed time: 3.152\n",
      "Computing distances for sample #1701/4001, elapsed time: 3.299\n",
      "Computing distances for sample #1801/4001, elapsed time: 3.479\n",
      "Computing distances for sample #1901/4001, elapsed time: 3.627\n",
      "Computing distances for sample #2001/4001, elapsed time: 3.805\n",
      "Computing distances for sample #2101/4001, elapsed time: 3.943\n",
      "Computing distances for sample #2201/4001, elapsed time: 4.117\n",
      "Computing distances for sample #2301/4001, elapsed time: 4.358\n",
      "Computing distances for sample #2401/4001, elapsed time: 4.517\n",
      "Computing distances for sample #2501/4001, elapsed time: 4.645\n",
      "Computing distances for sample #2601/4001, elapsed time: 4.781\n",
      "Computing distances for sample #2701/4001, elapsed time: 4.911\n",
      "Computing distances for sample #2801/4001, elapsed time: 5.052\n",
      "Computing distances for sample #2901/4001, elapsed time: 5.231\n",
      "Computing distances for sample #3001/4001, elapsed time: 5.360\n",
      "Computing distances for sample #3101/4001, elapsed time: 5.512\n",
      "Computing distances for sample #3201/4001, elapsed time: 5.639\n",
      "Computing distances for sample #3301/4001, elapsed time: 5.791\n",
      "Computing distances for sample #3401/4001, elapsed time: 5.933\n",
      "Computing distances for sample #3501/4001, elapsed time: 6.085\n",
      "Computing distances for sample #3601/4001, elapsed time: 6.208\n",
      "Computing distances for sample #3701/4001, elapsed time: 6.354\n",
      "Computing distances for sample #3801/4001, elapsed time: 6.481\n",
      "Computing distances for sample #3901/4001, elapsed time: 6.620\n",
      "Computing distances for sample #4001/4001, elapsed time: 6.745\n",
      "Imputing row 1/4001 with 32 missing columns, elapsed time: 7.912\n",
      "Imputing row 101/4001 with 32 missing columns, elapsed time: 8.086\n",
      "Imputing row 201/4001 with 28 missing columns, elapsed time: 8.213\n",
      "Imputing row 301/4001 with 26 missing columns, elapsed time: 8.326\n",
      "Imputing row 401/4001 with 27 missing columns, elapsed time: 8.454\n",
      "Imputing row 501/4001 with 27 missing columns, elapsed time: 8.572\n",
      "Imputing row 601/4001 with 25 missing columns, elapsed time: 8.696\n",
      "Imputing row 701/4001 with 28 missing columns, elapsed time: 8.818\n",
      "Imputing row 801/4001 with 28 missing columns, elapsed time: 8.951\n",
      "Imputing row 901/4001 with 31 missing columns, elapsed time: 9.074\n",
      "Imputing row 1001/4001 with 26 missing columns, elapsed time: 9.197\n",
      "Imputing row 1101/4001 with 28 missing columns, elapsed time: 9.310\n",
      "Imputing row 1201/4001 with 34 missing columns, elapsed time: 9.435\n",
      "Imputing row 1301/4001 with 36 missing columns, elapsed time: 9.566\n",
      "Imputing row 1401/4001 with 30 missing columns, elapsed time: 9.691\n",
      "Imputing row 1501/4001 with 33 missing columns, elapsed time: 9.805\n",
      "Imputing row 1601/4001 with 32 missing columns, elapsed time: 9.926\n",
      "Imputing row 1701/4001 with 35 missing columns, elapsed time: 10.054\n",
      "Imputing row 1801/4001 with 30 missing columns, elapsed time: 10.181\n",
      "Imputing row 1901/4001 with 26 missing columns, elapsed time: 10.298\n",
      "Imputing row 2001/4001 with 27 missing columns, elapsed time: 10.422\n",
      "Imputing row 2101/4001 with 31 missing columns, elapsed time: 10.536\n",
      "Imputing row 2201/4001 with 31 missing columns, elapsed time: 10.669\n",
      "Imputing row 2301/4001 with 25 missing columns, elapsed time: 10.790\n",
      "Imputing row 2401/4001 with 26 missing columns, elapsed time: 10.910\n",
      "Imputing row 2501/4001 with 26 missing columns, elapsed time: 11.030\n",
      "Imputing row 2601/4001 with 30 missing columns, elapsed time: 11.158\n",
      "Imputing row 2701/4001 with 30 missing columns, elapsed time: 11.280\n",
      "Imputing row 2801/4001 with 30 missing columns, elapsed time: 11.404\n",
      "Imputing row 2901/4001 with 24 missing columns, elapsed time: 11.524\n",
      "Imputing row 3001/4001 with 31 missing columns, elapsed time: 11.654\n",
      "Imputing row 3101/4001 with 30 missing columns, elapsed time: 11.771\n",
      "Imputing row 3201/4001 with 33 missing columns, elapsed time: 11.898\n",
      "Imputing row 3301/4001 with 28 missing columns, elapsed time: 12.018\n",
      "Imputing row 3401/4001 with 29 missing columns, elapsed time: 12.144\n",
      "Imputing row 3501/4001 with 25 missing columns, elapsed time: 12.265\n",
      "Imputing row 3601/4001 with 31 missing columns, elapsed time: 12.386\n",
      "Imputing row 3701/4001 with 29 missing columns, elapsed time: 12.504\n",
      "Imputing row 3801/4001 with 30 missing columns, elapsed time: 12.629\n",
      "Imputing row 3901/4001 with 30 missing columns, elapsed time: 12.751\n",
      "Imputing row 4001/4001 with 31 missing columns, elapsed time: 12.872\n"
     ]
    }
   ],
   "source": [
    "alldata_filled_KNN = KNN(k=5).complete(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49172166,  1.26428685, -0.15857676, -0.15076807,  1.08762723,\n",
       "        0.15716598, -1.05387929, -1.1169605 , -0.5164186 ,  0.26278957,\n",
       "        1.04783908,  0.94763389,  0.60168794, -0.23575826,  0.17582961,\n",
       "        0.39246612,  0.1078882 ,  0.01666201, -0.04175543, -0.04732615,\n",
       "       -0.39925639,  0.02492688,  0.22150317, -0.01160996, -0.13586108,\n",
       "        0.28304116, -0.11541101,  0.16440892, -0.39185438,  0.34897147,\n",
       "        0.06626888,  0.61581002,  1.42047292, -0.37906425,  0.37902754,\n",
       "        0.11845125,  0.43864351, -0.26293731, -0.1378807 ,  0.18950561,\n",
       "        0.88755757, -0.10337045, -0.40572264, -0.99622344, -0.03962045,\n",
       "        1.07679487,  5.2844729 ,  0.19530428, -0.37605104, -0.61527922,  0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_filled_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colonnenames=['x'+str(j) for j in range(1,52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datacomplete=pd.DataFrame(alldata_filled_KNN)\n",
    "datacomplete.index=alldata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datacomplete.columns=colonnenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "      <th>x40</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "      <th>x51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">train</th>\n",
       "      <th>0</th>\n",
       "      <td>0.491722</td>\n",
       "      <td>1.264287</td>\n",
       "      <td>-0.158577</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>1.087627</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>-1.053879</td>\n",
       "      <td>-1.116961</td>\n",
       "      <td>-0.516419</td>\n",
       "      <td>0.262790</td>\n",
       "      <td>1.047839</td>\n",
       "      <td>0.947634</td>\n",
       "      <td>0.601688</td>\n",
       "      <td>-0.235758</td>\n",
       "      <td>0.175830</td>\n",
       "      <td>0.392466</td>\n",
       "      <td>0.107888</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>-0.041755</td>\n",
       "      <td>-0.047326</td>\n",
       "      <td>-0.399256</td>\n",
       "      <td>0.024927</td>\n",
       "      <td>0.221503</td>\n",
       "      <td>-0.011610</td>\n",
       "      <td>-0.135861</td>\n",
       "      <td>0.283041</td>\n",
       "      <td>-0.115411</td>\n",
       "      <td>0.164409</td>\n",
       "      <td>-0.391854</td>\n",
       "      <td>0.348971</td>\n",
       "      <td>0.066269</td>\n",
       "      <td>0.615810</td>\n",
       "      <td>1.420473</td>\n",
       "      <td>-0.379064</td>\n",
       "      <td>0.379028</td>\n",
       "      <td>0.118451</td>\n",
       "      <td>0.438644</td>\n",
       "      <td>-0.262937</td>\n",
       "      <td>-0.137881</td>\n",
       "      <td>0.189506</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>-0.103370</td>\n",
       "      <td>-0.405723</td>\n",
       "      <td>-0.996223</td>\n",
       "      <td>-0.039620</td>\n",
       "      <td>1.076795</td>\n",
       "      <td>5.284473</td>\n",
       "      <td>0.195304</td>\n",
       "      <td>-0.376051</td>\n",
       "      <td>-0.615279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249351</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>-0.040435</td>\n",
       "      <td>0.105421</td>\n",
       "      <td>-1.098919</td>\n",
       "      <td>0.289237</td>\n",
       "      <td>-0.338154</td>\n",
       "      <td>0.129297</td>\n",
       "      <td>0.807200</td>\n",
       "      <td>-0.594330</td>\n",
       "      <td>-0.581096</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>0.195210</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>-0.052029</td>\n",
       "      <td>-0.467408</td>\n",
       "      <td>-0.179635</td>\n",
       "      <td>0.074411</td>\n",
       "      <td>-0.105522</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>-0.736507</td>\n",
       "      <td>-0.068438</td>\n",
       "      <td>-0.417189</td>\n",
       "      <td>0.087101</td>\n",
       "      <td>-0.362549</td>\n",
       "      <td>0.270641</td>\n",
       "      <td>-0.657171</td>\n",
       "      <td>0.351780</td>\n",
       "      <td>0.510574</td>\n",
       "      <td>0.568804</td>\n",
       "      <td>0.248886</td>\n",
       "      <td>0.445685</td>\n",
       "      <td>0.169736</td>\n",
       "      <td>0.051006</td>\n",
       "      <td>0.089067</td>\n",
       "      <td>-0.171755</td>\n",
       "      <td>-0.329228</td>\n",
       "      <td>-0.203004</td>\n",
       "      <td>-0.413300</td>\n",
       "      <td>0.225627</td>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.468655</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>0.527339</td>\n",
       "      <td>-0.291376</td>\n",
       "      <td>-0.165093</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>1.096701</td>\n",
       "      <td>0.658806</td>\n",
       "      <td>0.577559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.986824</td>\n",
       "      <td>-0.189678</td>\n",
       "      <td>0.059693</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.777260</td>\n",
       "      <td>-1.051633</td>\n",
       "      <td>-1.011747</td>\n",
       "      <td>-0.756690</td>\n",
       "      <td>-0.696582</td>\n",
       "      <td>0.874877</td>\n",
       "      <td>-0.273440</td>\n",
       "      <td>0.086508</td>\n",
       "      <td>0.688904</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.182287</td>\n",
       "      <td>0.351119</td>\n",
       "      <td>-0.327590</td>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.154479</td>\n",
       "      <td>0.290977</td>\n",
       "      <td>0.956582</td>\n",
       "      <td>0.388028</td>\n",
       "      <td>0.191073</td>\n",
       "      <td>0.086748</td>\n",
       "      <td>1.195586</td>\n",
       "      <td>0.310467</td>\n",
       "      <td>0.202824</td>\n",
       "      <td>0.131217</td>\n",
       "      <td>-0.870593</td>\n",
       "      <td>0.348219</td>\n",
       "      <td>0.286557</td>\n",
       "      <td>0.452968</td>\n",
       "      <td>0.402763</td>\n",
       "      <td>-1.309222</td>\n",
       "      <td>0.406656</td>\n",
       "      <td>0.296849</td>\n",
       "      <td>0.264740</td>\n",
       "      <td>0.427946</td>\n",
       "      <td>0.513461</td>\n",
       "      <td>0.320219</td>\n",
       "      <td>0.404907</td>\n",
       "      <td>-0.271227</td>\n",
       "      <td>-0.282350</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.480180</td>\n",
       "      <td>-0.518204</td>\n",
       "      <td>-0.105363</td>\n",
       "      <td>-0.541989</td>\n",
       "      <td>-0.461882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.265990</td>\n",
       "      <td>-0.517960</td>\n",
       "      <td>-0.114526</td>\n",
       "      <td>-0.073818</td>\n",
       "      <td>1.889234</td>\n",
       "      <td>-0.161217</td>\n",
       "      <td>-0.947844</td>\n",
       "      <td>-0.650268</td>\n",
       "      <td>-0.712451</td>\n",
       "      <td>1.178903</td>\n",
       "      <td>0.126789</td>\n",
       "      <td>0.596843</td>\n",
       "      <td>0.788205</td>\n",
       "      <td>0.131752</td>\n",
       "      <td>0.423003</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>-0.223991</td>\n",
       "      <td>0.030660</td>\n",
       "      <td>-0.081760</td>\n",
       "      <td>0.246647</td>\n",
       "      <td>0.044999</td>\n",
       "      <td>0.285686</td>\n",
       "      <td>-0.455399</td>\n",
       "      <td>-0.077836</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>0.286065</td>\n",
       "      <td>0.310761</td>\n",
       "      <td>-0.703435</td>\n",
       "      <td>0.465727</td>\n",
       "      <td>0.240896</td>\n",
       "      <td>0.822045</td>\n",
       "      <td>0.497331</td>\n",
       "      <td>-1.189501</td>\n",
       "      <td>0.242710</td>\n",
       "      <td>0.440182</td>\n",
       "      <td>0.373681</td>\n",
       "      <td>-0.184058</td>\n",
       "      <td>0.686641</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.430068</td>\n",
       "      <td>-0.108483</td>\n",
       "      <td>-0.378151</td>\n",
       "      <td>0.219661</td>\n",
       "      <td>-0.431705</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>-0.216563</td>\n",
       "      <td>0.479940</td>\n",
       "      <td>-0.755457</td>\n",
       "      <td>-0.526293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199900</td>\n",
       "      <td>-0.095447</td>\n",
       "      <td>0.263825</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>-1.125166</td>\n",
       "      <td>-1.318912</td>\n",
       "      <td>-0.887661</td>\n",
       "      <td>-1.202686</td>\n",
       "      <td>-0.304145</td>\n",
       "      <td>-0.413741</td>\n",
       "      <td>-0.806276</td>\n",
       "      <td>0.415610</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>0.010513</td>\n",
       "      <td>0.302067</td>\n",
       "      <td>-0.036239</td>\n",
       "      <td>-0.290726</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>-0.541424</td>\n",
       "      <td>0.204252</td>\n",
       "      <td>-1.118377</td>\n",
       "      <td>-0.014610</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>2.624526</td>\n",
       "      <td>0.983099</td>\n",
       "      <td>-1.652295</td>\n",
       "      <td>-1.170604</td>\n",
       "      <td>0.388641</td>\n",
       "      <td>1.233810</td>\n",
       "      <td>0.349228</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>-2.776458</td>\n",
       "      <td>-0.118833</td>\n",
       "      <td>0.330532</td>\n",
       "      <td>0.168075</td>\n",
       "      <td>-1.209992</td>\n",
       "      <td>0.299191</td>\n",
       "      <td>0.033525</td>\n",
       "      <td>0.040870</td>\n",
       "      <td>0.393697</td>\n",
       "      <td>-0.424390</td>\n",
       "      <td>-0.568337</td>\n",
       "      <td>-0.180425</td>\n",
       "      <td>0.887360</td>\n",
       "      <td>-0.686345</td>\n",
       "      <td>-0.699968</td>\n",
       "      <td>-0.355482</td>\n",
       "      <td>0.179848</td>\n",
       "      <td>-0.241917</td>\n",
       "      <td>-0.535741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1        x2        x3        x4        x5        x6        x7  \\\n",
       "train 0  0.491722  1.264287 -0.158577 -0.150768  1.087627  0.157166 -1.053879   \n",
       "      1 -0.249351  0.046088 -0.040435  0.105421 -1.098919  0.289237 -0.338154   \n",
       "      2  0.986824 -0.189678  0.059693  0.010147  0.777260 -1.051633 -1.011747   \n",
       "      3 -0.265990 -0.517960 -0.114526 -0.073818  1.889234 -0.161217 -0.947844   \n",
       "      4  0.199900 -0.095447  0.263825  0.040790 -1.125166 -1.318912 -0.887661   \n",
       "\n",
       "               x8        x9       x10       x11       x12       x13       x14  \\\n",
       "train 0 -1.116961 -0.516419  0.262790  1.047839  0.947634  0.601688 -0.235758   \n",
       "      1  0.129297  0.807200 -0.594330 -0.581096  0.013371  0.195210  0.010919   \n",
       "      2 -0.756690 -0.696582  0.874877 -0.273440  0.086508  0.688904  0.011214   \n",
       "      3 -0.650268 -0.712451  1.178903  0.126789  0.596843  0.788205  0.131752   \n",
       "      4 -1.202686 -0.304145 -0.413741 -0.806276  0.415610  0.060390  0.010513   \n",
       "\n",
       "              x15       x16       x17       x18       x19       x20       x21  \\\n",
       "train 0  0.175830  0.392466  0.107888  0.016662 -0.041755 -0.047326 -0.399256   \n",
       "      1 -0.052029 -0.467408 -0.179635  0.074411 -0.105522  0.008015 -0.736507   \n",
       "      2  0.182287  0.351119 -0.327590  0.026406  0.154479  0.290977  0.956582   \n",
       "      3  0.423003  0.150610 -0.223991  0.030660 -0.081760  0.246647  0.044999   \n",
       "      4  0.302067 -0.036239 -0.290726  0.037814 -0.541424  0.204252 -1.118377   \n",
       "\n",
       "              x22       x23       x24       x25       x26       x27       x28  \\\n",
       "train 0  0.024927  0.221503 -0.011610 -0.135861  0.283041 -0.115411  0.164409   \n",
       "      1 -0.068438 -0.417189  0.087101 -0.362549  0.270641 -0.657171  0.351780   \n",
       "      2  0.388028  0.191073  0.086748  1.195586  0.310467  0.202824  0.131217   \n",
       "      3  0.285686 -0.455399 -0.077836  0.111350  0.271222  0.286065  0.310761   \n",
       "      4 -0.014610 -0.012254  2.624526  0.983099 -1.652295 -1.170604  0.388641   \n",
       "\n",
       "              x29       x30       x31       x32       x33       x34       x35  \\\n",
       "train 0 -0.391854  0.348971  0.066269  0.615810  1.420473 -0.379064  0.379028   \n",
       "      1  0.510574  0.568804  0.248886  0.445685  0.169736  0.051006  0.089067   \n",
       "      2 -0.870593  0.348219  0.286557  0.452968  0.402763 -1.309222  0.406656   \n",
       "      3 -0.703435  0.465727  0.240896  0.822045  0.497331 -1.189501  0.242710   \n",
       "      4  1.233810  0.349228 -0.061911 -2.776458 -0.118833  0.330532  0.168075   \n",
       "\n",
       "              x36       x37       x38       x39       x40       x41       x42  \\\n",
       "train 0  0.118451  0.438644 -0.262937 -0.137881  0.189506  0.887558 -0.103370   \n",
       "      1 -0.171755 -0.329228 -0.203004 -0.413300  0.225627  0.049266  0.468655   \n",
       "      2  0.296849  0.264740  0.427946  0.513461  0.320219  0.404907 -0.271227   \n",
       "      3  0.440182  0.373681 -0.184058  0.686641  0.117178  0.430068 -0.108483   \n",
       "      4 -1.209992  0.299191  0.033525  0.040870  0.393697 -0.424390 -0.568337   \n",
       "\n",
       "              x43       x44       x45       x46       x47       x48       x49  \\\n",
       "train 0 -0.405723 -0.996223 -0.039620  1.076795  5.284473  0.195304 -0.376051   \n",
       "      1  0.083019  0.527339 -0.291376 -0.165093  0.652600  1.096701  0.658806   \n",
       "      2 -0.282350  0.995816  0.004617  0.480180 -0.518204 -0.105363 -0.541989   \n",
       "      3 -0.378151  0.219661 -0.431705  0.743919 -0.216563  0.479940 -0.755457   \n",
       "      4 -0.180425  0.887360 -0.686345 -0.699968 -0.355482  0.179848 -0.241917   \n",
       "\n",
       "              x50  x51  \n",
       "train 0 -0.615279  0.0  \n",
       "      1  0.577559  0.0  \n",
       "      2 -0.461882  0.0  \n",
       "      3 -0.526293  0.0  \n",
       "      4 -0.535741  0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacomplete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_nan_KNN=datacomplete.ix['test']\n",
    "train_nan_KNN=datacomplete.ix['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 640 out of 640 | elapsed: 18.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 20, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.958 (+/-0.037) for {'max_features': 5, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.958 (+/-0.027) for {'max_features': 5, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.956 (+/-0.037) for {'max_features': 10, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.962 (+/-0.031) for {'max_features': 10, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.958 (+/-0.028) for {'max_features': 20, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.962 (+/-0.028) for {'max_features': 20, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.957 (+/-0.028) for {'max_features': 50, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.957 (+/-0.033) for {'max_features': 50, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.958 (+/-0.035) for {'max_features': 5, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.960 (+/-0.026) for {'max_features': 5, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.960 (+/-0.028) for {'max_features': 10, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.961 (+/-0.029) for {'max_features': 10, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.960 (+/-0.034) for {'max_features': 20, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.964 (+/-0.028) for {'max_features': 20, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.961 (+/-0.031) for {'max_features': 50, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.961 (+/-0.032) for {'max_features': 50, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.958 (+/-0.031) for {'max_features': 5, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.955 (+/-0.036) for {'max_features': 5, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.958 (+/-0.033) for {'max_features': 10, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.959 (+/-0.035) for {'max_features': 10, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.959 (+/-0.037) for {'max_features': 20, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.958 (+/-0.025) for {'max_features': 20, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.951 (+/-0.030) for {'max_features': 50, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.952 (+/-0.029) for {'max_features': 50, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.954 (+/-0.031) for {'max_features': 5, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.957 (+/-0.032) for {'max_features': 5, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.959 (+/-0.028) for {'max_features': 10, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.957 (+/-0.030) for {'max_features': 10, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.956 (+/-0.030) for {'max_features': 20, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.958 (+/-0.029) for {'max_features': 20, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.929 (+/-0.039) for {'max_features': 50, 'n_estimators': 100, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.931 (+/-0.043) for {'max_features': 50, 'n_estimators': 300, 'loss': 'deviance', 'max_depth': 30}\n",
      "0.953 (+/-0.030) for {'max_features': 5, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.960 (+/-0.025) for {'max_features': 5, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.956 (+/-0.027) for {'max_features': 10, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.958 (+/-0.027) for {'max_features': 10, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.958 (+/-0.022) for {'max_features': 20, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.960 (+/-0.027) for {'max_features': 20, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.955 (+/-0.031) for {'max_features': 50, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.958 (+/-0.027) for {'max_features': 50, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.956 (+/-0.027) for {'max_features': 5, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.962 (+/-0.028) for {'max_features': 5, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.956 (+/-0.026) for {'max_features': 10, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.960 (+/-0.027) for {'max_features': 10, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.960 (+/-0.032) for {'max_features': 20, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.962 (+/-0.028) for {'max_features': 20, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.960 (+/-0.027) for {'max_features': 50, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.962 (+/-0.033) for {'max_features': 50, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.959 (+/-0.029) for {'max_features': 5, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.958 (+/-0.029) for {'max_features': 5, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.958 (+/-0.033) for {'max_features': 10, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.959 (+/-0.029) for {'max_features': 10, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.958 (+/-0.026) for {'max_features': 20, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.958 (+/-0.036) for {'max_features': 20, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.953 (+/-0.028) for {'max_features': 50, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.953 (+/-0.037) for {'max_features': 50, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.957 (+/-0.029) for {'max_features': 5, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.958 (+/-0.030) for {'max_features': 5, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.960 (+/-0.029) for {'max_features': 10, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.959 (+/-0.031) for {'max_features': 10, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.956 (+/-0.031) for {'max_features': 20, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.957 (+/-0.031) for {'max_features': 20, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.930 (+/-0.037) for {'max_features': 50, 'n_estimators': 100, 'loss': 'exponential', 'max_depth': 30}\n",
      "0.931 (+/-0.042) for {'max_features': 50, 'n_estimators': 300, 'loss': 'exponential', 'max_depth': 30}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'loss': ['deviance','exponential'],\n",
    "                    'max_features':[5,10,20,50],\n",
    "                    'max_depth':[3,5,10,30],\n",
    "                    'n_estimators':[100,300]}]\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), tuned_parameters, cv=10,verbose=1)\n",
    "clf.fit(train_nan_KNN, cible[0].values)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96375"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance', 'max_depth': 5, 'max_features': 20, 'n_estimators': 300}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=20, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=300, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(loss='deviance',max_depth=5,max_features=20,n_estimators=300)\n",
    "clf.fit(train_nan_KNN, cible[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_clf=clf.predict(test_nan_KNN)\n",
    "\n",
    "index=range(len(y_pred_clf))\n",
    "data=np.transpose([index,y_pred_clf])\n",
    "a = pd.DataFrame(data=data,columns=['Id','Prediction'])\n",
    "a.to_csv(\"submission9.csv\", sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=GradientBoostingClassifier(loss='deviance',max_depth=5,max_features=20,n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BC=BaggingClassifier(base_estimator=clf,n_estimators=50,oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=20, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=300, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=50, n_jobs=1, oob_score=True,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.fit(train_nan_KNN, cible[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96083333333333332"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_clf=BC.predict(test_nan_KNN)\n",
    "\n",
    "index=range(len(y_pred_clf))\n",
    "data=np.transpose([index,y_pred_clf])\n",
    "a = pd.DataFrame(data=data,columns=['Id','Prediction'])\n",
    "a.to_csv(\"submission10.csv\", sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diminuer/augmenter knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances between 4001 samples\n",
      "Computing distances for sample #1/4001, elapsed time: 0.750\n",
      "Computing distances for sample #101/4001, elapsed time: 0.889\n",
      "Computing distances for sample #201/4001, elapsed time: 1.027\n",
      "Computing distances for sample #301/4001, elapsed time: 1.185\n",
      "Computing distances for sample #401/4001, elapsed time: 1.339\n",
      "Computing distances for sample #501/4001, elapsed time: 1.463\n",
      "Computing distances for sample #601/4001, elapsed time: 1.604\n",
      "Computing distances for sample #701/4001, elapsed time: 1.741\n",
      "Computing distances for sample #801/4001, elapsed time: 1.883\n",
      "Computing distances for sample #901/4001, elapsed time: 2.010\n",
      "Computing distances for sample #1001/4001, elapsed time: 2.186\n",
      "Computing distances for sample #1101/4001, elapsed time: 2.352\n",
      "Computing distances for sample #1201/4001, elapsed time: 2.506\n",
      "Computing distances for sample #1301/4001, elapsed time: 2.648\n",
      "Computing distances for sample #1401/4001, elapsed time: 2.819\n",
      "Computing distances for sample #1501/4001, elapsed time: 2.976\n",
      "Computing distances for sample #1601/4001, elapsed time: 3.161\n",
      "Computing distances for sample #1701/4001, elapsed time: 3.569\n",
      "Computing distances for sample #1801/4001, elapsed time: 3.737\n",
      "Computing distances for sample #1901/4001, elapsed time: 3.940\n",
      "Computing distances for sample #2001/4001, elapsed time: 4.096\n",
      "Computing distances for sample #2101/4001, elapsed time: 4.263\n",
      "Computing distances for sample #2201/4001, elapsed time: 4.430\n",
      "Computing distances for sample #2301/4001, elapsed time: 4.587\n",
      "Computing distances for sample #2401/4001, elapsed time: 4.738\n",
      "Computing distances for sample #2501/4001, elapsed time: 4.901\n",
      "Computing distances for sample #2601/4001, elapsed time: 5.062\n",
      "Computing distances for sample #2701/4001, elapsed time: 5.216\n",
      "Computing distances for sample #2801/4001, elapsed time: 5.428\n",
      "Computing distances for sample #2901/4001, elapsed time: 5.578\n",
      "Computing distances for sample #3001/4001, elapsed time: 5.739\n",
      "Computing distances for sample #3101/4001, elapsed time: 5.890\n",
      "Computing distances for sample #3201/4001, elapsed time: 6.037\n",
      "Computing distances for sample #3301/4001, elapsed time: 6.199\n",
      "Computing distances for sample #3401/4001, elapsed time: 6.350\n",
      "Computing distances for sample #3501/4001, elapsed time: 6.494\n",
      "Computing distances for sample #3601/4001, elapsed time: 6.639\n",
      "Computing distances for sample #3701/4001, elapsed time: 6.785\n",
      "Computing distances for sample #3801/4001, elapsed time: 6.932\n",
      "Computing distances for sample #3901/4001, elapsed time: 7.078\n",
      "Computing distances for sample #4001/4001, elapsed time: 7.227\n",
      "Imputing row 1/4001 with 32 missing columns, elapsed time: 8.417\n",
      "Imputing row 101/4001 with 32 missing columns, elapsed time: 8.545\n",
      "Imputing row 201/4001 with 28 missing columns, elapsed time: 8.672\n",
      "Imputing row 301/4001 with 26 missing columns, elapsed time: 8.804\n",
      "Imputing row 401/4001 with 27 missing columns, elapsed time: 8.933\n",
      "Imputing row 501/4001 with 27 missing columns, elapsed time: 9.062\n",
      "Imputing row 601/4001 with 25 missing columns, elapsed time: 9.189\n",
      "Imputing row 701/4001 with 28 missing columns, elapsed time: 9.319\n",
      "Imputing row 801/4001 with 28 missing columns, elapsed time: 9.458\n",
      "Imputing row 901/4001 with 31 missing columns, elapsed time: 9.591\n",
      "Imputing row 1001/4001 with 26 missing columns, elapsed time: 9.716\n",
      "Imputing row 1101/4001 with 28 missing columns, elapsed time: 9.843\n",
      "Imputing row 1201/4001 with 34 missing columns, elapsed time: 9.975\n",
      "Imputing row 1301/4001 with 36 missing columns, elapsed time: 10.105\n",
      "Imputing row 1401/4001 with 30 missing columns, elapsed time: 10.246\n",
      "Imputing row 1501/4001 with 33 missing columns, elapsed time: 10.378\n",
      "Imputing row 1601/4001 with 32 missing columns, elapsed time: 10.502\n",
      "Imputing row 1701/4001 with 35 missing columns, elapsed time: 10.636\n",
      "Imputing row 1801/4001 with 30 missing columns, elapsed time: 10.773\n",
      "Imputing row 1901/4001 with 26 missing columns, elapsed time: 10.907\n",
      "Imputing row 2001/4001 with 27 missing columns, elapsed time: 11.047\n",
      "Imputing row 2101/4001 with 31 missing columns, elapsed time: 11.184\n",
      "Imputing row 2201/4001 with 31 missing columns, elapsed time: 11.320\n",
      "Imputing row 2301/4001 with 25 missing columns, elapsed time: 11.452\n",
      "Imputing row 2401/4001 with 26 missing columns, elapsed time: 11.586\n",
      "Imputing row 2501/4001 with 26 missing columns, elapsed time: 11.719\n",
      "Imputing row 2601/4001 with 30 missing columns, elapsed time: 11.853\n",
      "Imputing row 2701/4001 with 30 missing columns, elapsed time: 11.989\n",
      "Imputing row 2801/4001 with 30 missing columns, elapsed time: 12.124\n",
      "Imputing row 2901/4001 with 24 missing columns, elapsed time: 12.260\n",
      "Imputing row 3001/4001 with 31 missing columns, elapsed time: 12.390\n",
      "Imputing row 3101/4001 with 30 missing columns, elapsed time: 12.520\n",
      "Imputing row 3201/4001 with 33 missing columns, elapsed time: 12.652\n",
      "Imputing row 3301/4001 with 28 missing columns, elapsed time: 12.782\n",
      "Imputing row 3401/4001 with 29 missing columns, elapsed time: 12.908\n",
      "Imputing row 3501/4001 with 25 missing columns, elapsed time: 13.038\n",
      "Imputing row 3601/4001 with 31 missing columns, elapsed time: 13.170\n",
      "Imputing row 3701/4001 with 29 missing columns, elapsed time: 13.302\n",
      "Imputing row 3801/4001 with 30 missing columns, elapsed time: 13.438\n",
      "Imputing row 3901/4001 with 30 missing columns, elapsed time: 13.586\n",
      "Imputing row 4001/4001 with 31 missing columns, elapsed time: 13.728\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9182128d5dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_nan_KNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcible\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alldata_filled_KNN = KNN(k=9).complete(alldata)\n",
    "alldata_filled_KNN\n",
    "colonnenames=['x'+str(j) for j in range(1,52)]\n",
    "datacomplete=pd.DataFrame(alldata_filled_KNN)\n",
    "datacomplete.index=alldata.index\n",
    "datacomplete.columns=colonnenames\n",
    "test_nan_KNN=datacomplete.ix['test']\n",
    "train_nan_KNN=datacomplete.ix['train']\n",
    "tuned_parameters = [{'loss': ['deviance','exponential'],\n",
    "                    'max_features':[5,10,20,50],\n",
    "                    'max_depth':[3,5,10,30],\n",
    "                    'n_estimators':[100,300]}]\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), tuned_parameters, cv=10,verbose=1)\n",
    "clf.fit(train_nan_KNN, cible[0].values)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
